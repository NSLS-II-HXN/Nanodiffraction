{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raising-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%5|1740585423.514|CONFWARN|rdkafka#producer-1| [thrd:app]: No `bootstrap.servers` configured: client will not be able to connect to Kafka cluster\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib\n",
    "from nanorsm_v2 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf19b4a",
   "metadata": {},
   "source": [
    "# Load XRF data for stack registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//data//users//current_user//XRF//output_tiff_scan2D_330770/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330772/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330774/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330776/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330778/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330780/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330782/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330784/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330786/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330788/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330790/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330792/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330794/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330796/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330798/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330800/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330802/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330804/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330806/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330808/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330810/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330812/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330814/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330816/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330818/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330820/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330822/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330824/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330826/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330828/detsum_Ta_L_norm.tiff\n",
      "//data//users//current_user//XRF//output_tiff_scan2D_330830/detsum_Ta_L_norm.tiff\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3cf5b61b8748d59bd7f8847491bb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30fcb45abe1470291be8307ef759f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load elemental image data, align it with pystackreg and generate a tranform matrix\n",
    "#put xrf data with a filena\n",
    "\n",
    "det_params = {'merlin1':55, \"merlin2\":55, \"eiger\":75}\n",
    "\n",
    "logfile = '//data//users//current_user/Find_ideal_theta_scan_startID330770.csv'\n",
    "\n",
    "xrf_folder = '//data//users//current_user//XRF//'\n",
    "elem = 'Ta_L'\n",
    "diff_detector = 'merlin1'\n",
    "\n",
    "df = pd.read_csv(logfile)\n",
    "sid_list = df['scan_id'].to_numpy(dtype = 'int')\n",
    "angles = df['angle'].to_numpy()\n",
    "#sid_list = get_sid_list(['218921-219056'],3)\n",
    "\n",
    "\n",
    "num = np.size(sid_list)\n",
    "file_list = []\n",
    "for sid in sid_list:\n",
    "    \n",
    "    tmp = os.path.join(xrf_folder, f'output_tiff_scan2D_{int(sid)}/detsum_{elem}_norm.tiff')\n",
    "    print(tmp)\n",
    "    file_list.append(tmp)\n",
    "im_stack = load_ims(file_list)\n",
    "\n",
    "num_frame,im_row,im_col = np.shape(im_stack)\n",
    "\n",
    "im_stack_aligned, trans_matrix = align_im_stack(im_stack) # use pystackreg\n",
    "\n",
    "#im_stack = np.delete(im_stack,0,axis=0)\n",
    "#trans_matrix = np.delete(trans_matrix,0,axis=0)\n",
    "\n",
    "im_stack_test = interp_sub_pix(im_stack,trans_matrix) # verify the alignment is done correctly\n",
    "\n",
    "\n",
    "dir_ = os.path.abspath(os.path.dirname(logfile))\n",
    "folder_name = os.path.basename(logfile).split('.')[0]\n",
    "save_folder =  os.path.join(dir_,folder_name+\"_diff_data\")\n",
    "data_path = save_folder\n",
    "\n",
    "os.makedirs(save_folder, exist_ok = True)\n",
    "                                \n",
    "xrf_savename = os.path.join(save_folder,f\"aligned_xrf_stack_{elem}.tiff\")\n",
    "\n",
    "tf.imwrite(xrf_savename,im_stack_test.astype(np.float32),imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7746b",
   "metadata": {},
   "source": [
    "# Apply stack alignemnt to other elemenets (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "residential-chart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44de1d54ad4bd4ae717a73468e87e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5676c74039be44e6a07ae3029821f249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if there are more elements to be aligned and stacked\n",
    "elem_list = ['Ni_K']\n",
    "#sid_list = get_sid_list(['219792-219888'],3)\n",
    "\n",
    "num = np.size(sid_list)\n",
    "i = 1\n",
    "for elem in elem_list:\n",
    "    file_list = []\n",
    "    for sid in sid_list:\n",
    "        tmp = os.path.join(xrf_folder, f'output_tiff_scan2D_{int(sid)}/detsum_{elem}_norm.tiff')\n",
    "        \n",
    "        file_list.append(tmp)\n",
    "    im_stack = load_ims(file_list)\n",
    "    \n",
    "    im_stack_test = interp_sub_pix(im_stack,trans_matrix)\n",
    "    imp = np.sum(im_stack_test,0)\n",
    "    imp.shape\n",
    "    if i == 1:\n",
    "        stack = imp\n",
    "        sz = np.shape(imp)\n",
    "        stack = np.reshape(stack, (1,sz[0],sz[1]))\n",
    "    else:\n",
    "        stack = np.concatenate((stack,imp[np.newaxis,:,:]),0)\n",
    "    i = i+1\n",
    "    xrf_savename = os.path.join(save_folder,f\"aligned_xrf_stack_{elem}.tiff\")\n",
    "    tf.imwrite(xrf_savename,im_stack_test.astype(np.float32),imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7016a4",
   "metadata": {},
   "source": [
    "# Load a total sum of diffraction images to decide the ROI and any mask for diff images (Optional if ROI is decided before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-commerce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4e40ee624e4d3e8b4dc38193fd9f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2890924/1617494443.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  plt.imshow(np.log10(tot))\n"
     ]
    }
   ],
   "source": [
    "#sid_list = get_sid_list(['219422'],1)\n",
    "tot = sum_all_h5_data_db(sid_list,diff_detector) \n",
    "plt.figure()\n",
    "plt.imshow(np.log10(tot))\n",
    "plt.savefig(os.path.join(save_folder,f\"total_sum_{diff_detector}_image.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86d850",
   "metadata": {},
   "source": [
    "# Apply a mask (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solar-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda_envs/nsls2-analysis-2021-1.2/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log10\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a92dcdf50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask = np.asarray(tifffile.imread('//data//users//2023Q2//Murray_2023Q2//nanodiffraction//mask.tif'))\n",
    "# plt.figure()\n",
    "# plt.imshow(np.log10(mask),clim=[0,5])\n",
    "plt.imshow(np.log10(tot*mask+0.1),clim=[0.1,3.5])\n",
    "#tifffile.imwrite('/data/users/2023Q2/Murray_2023Q2/Substrate_35_perc_sum_all.tif',tot.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e01390",
   "metadata": {},
   "source": [
    "# sum all diffraction patterns from local files to determine roi and mask (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_path = '//data//home//home//hyan//export//scan_180000//'\n",
    "#prefix = 'scan_'\n",
    "#postfix = '_merlin1.h5'\n",
    "\n",
    "#data_file_list = create_file_list(data_path, prefix, postfix, sid_list)\n",
    "#tot = sum_all_h5_data(data_file_list)\n",
    "#plt.imshow(np.log10(tot+0.1),clim=[1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine from tot image\n",
    "#mask = np.ones(tot.shape)\n",
    "\n",
    "#plt.imshow(np.log10(tot*mask+0.1))\n",
    "#roi = [185,105,160,130]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8c4f6",
   "metadata": {},
   "source": [
    "# Check the ROI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78b1eab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m roi \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mlog10(\u001b[43mtot\u001b[49m[roi[\u001b[38;5;241m0\u001b[39m]:roi[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mroi[\u001b[38;5;241m2\u001b[39m],roi[\u001b[38;5;241m1\u001b[39m]:roi[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mroi[\u001b[38;5;241m3\u001b[39m]]))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#mask = np.asarray(tifffile.imread('//data//users//2023Q2//Murray_2023Q2//nanodiffraction//mask.tif'))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROI_total_sum_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff_detector\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tot' is not defined"
     ]
    }
   ],
   "source": [
    "roi = [80,80,100,100]\n",
    "plt.imshow(np.log10(tot[roi[0]:roi[0]+roi[2],roi[1]:roi[1]+roi[3]]))\n",
    "#mask = np.asarray(tifffile.imread('//data//users//2023Q2//Murray_2023Q2//nanodiffraction//mask.tif'))\n",
    "plt.savefig(os.path.join(save_folder,f\"ROI_total_sum_{diff_detector}_image.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc4712",
   "metadata": {},
   "source": [
    "# Load, normalize, align, and assemble diffraction data through databroker\n",
    "# diff_data is the 5D dataset aligned; make sure your machine has enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "logical-breeding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92cc0412b884441bf3de3d2a2499e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scan points: 40000; raw image row: 247; raw image col: 255\n",
      "Total scan points: 40000; data image row: 100; data image col: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c73777fdf2472890604fe6bed1cdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scan_row,scan_col = get_diff_data_shape(sid_list)\n",
    "diff_data = load_h5_data_db(sid_list,det='merlin1', mon='sclr1_ch4', roi=roi)\n",
    "\n",
    "sz = diff_data.shape\n",
    "diff_data = np.reshape(diff_data,(sz[0],scan_row,scan_col,sz[2],sz[3]))\n",
    "diff_data = interp_sub_pix(diff_data,trans_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fe244",
   "metadata": {},
   "source": [
    "# check if images look normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indian-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(diff_data[5,20,20,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, normalize, align, and assemble diffraction data \n",
    "# diff_data is the 5D dataset aligned; make sure your machine has enough memory\n",
    "'''\n",
    "data_path = '//data//home//home//hyan//export//scan_180000//'\n",
    "prefix = 'scan_'\n",
    "postfix = '_merlin1.h5'\n",
    "scan_row = 100\n",
    "scan_col = 100\n",
    "\n",
    "data_file_list = create_file_list(data_path, prefix, postfix, sid_list)\n",
    "diff_data = load_h5_data(data_file_list,roi=roi,mask=mask)\n",
    "\n",
    "postfix = '_merlin1.txt'\n",
    "mon_file_list = create_file_list(data_path, prefix, postfix, sid_list)\n",
    "\n",
    "mon_data = load_scaler_data(mon_file_list,['sclr1_ch4'])\n",
    "\n",
    "# First scaler reading of each scan is zero; refill with first non-zero reading\n",
    "avg = np.mean(mon_data[mon_data != 0])\n",
    "mon_data[mon_data==0] = avg \n",
    "\n",
    "sz = diff_data.shape\n",
    "\n",
    "diff_data = (diff_data/mon_data[:,np.newaxis,np.newaxis])\n",
    "\n",
    "diff_data = np.reshape(diff_data,(sz[0],scan_row,scan_col,sz[2],sz[3]))\n",
    "diff_data = interp_sub_pix(diff_data,trans_matrix)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf473e5",
   "metadata": {},
   "source": [
    "# get diff det params from db or enter manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d47a33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n",
      "/nsls2/conda/envs/2023-1.0-py310-tiled/lib/python3.10/site-packages/databroker/eventsource/shim.py:266: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[field] = values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma, delta, dist: 14.999999999999998 20.40015714556238 500.00154456397104\n"
     ]
    }
   ],
   "source": [
    "energy,gamma,delta,det_dist = get_diff_det_params(int(sid_list[0]))\n",
    "pix = det_params[diff_detector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ambient-africa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf04f71508674903b37931fe64582f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw det_data is deleted\n",
      "qxz_data: [pos,qx,qz] with dimensions of (200, 200, 35, 758)\n",
      "qyz_data: [pos,qy,qz] with dimensions of (200, 200, 100, 758)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace4d1490fee4519a618179c163a4a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '//data/users/current_user/HoNiO3_p1_RT_startID313841_diff_data/_rsm//' created\n"
     ]
    }
   ],
   "source": [
    "# transform to cartesian crystal coordinates (z along hkl and x is the rocking direction)\n",
    "num_angle = len(sid_list)\n",
    "th_step = angles[1]-angles[0]\n",
    "offset = [0,0]\n",
    "data_store = 'reduced' # this will reduce the data stored. If use 'full' it can be over 100G\n",
    "save_path = os.path.join(save_folder,'_rsm//')\n",
    "\n",
    "# generate an object of the RSM class\n",
    "rsm = RSM(diff_data,energy,delta,gamma,num_angle,th_step,pix,det_dist,offset)\n",
    "# transform from detector coordinates to crystal coordinates\n",
    "rsm.calcRSM('cryst',data_store)\n",
    "# calculate strain\n",
    "# 'com', center of mass, is a simple algorithm to calculate the strain. Note: There is an abitrary offset\n",
    "rsm.calcSTRAIN('com')  \n",
    "# show results\n",
    "rsm.disp()\n",
    "# save results\n",
    "rsm.save(save_path)\n",
    "# also save the entire object\n",
    "save_file = ''.join([save_path,'rsm_.obj'])\n",
    "pickle.dump(rsm, open(save_file,'wb'),protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "previous-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = ''.join([data_path,'rsm_35_blanket_film.obj'])\n",
    "pickle.dump(rsm, open(save_file,'wb'),protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "incredible-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.log10(rsm.qxz_data[30,70,:,:].T+1e-7),clim=[-6,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '//data//users//2020Q3//Ajith_2020Q3//LPE_FeS2_P4_diff//'\n",
    "save_file = ''.join([data_path,'rsm.obj'])\n",
    "rsm = pickle.load(open(save_file,'rb'))\n",
    "rsm.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "virtual-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f291610e050>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.squeeze(np.sum(np.sum(diff_data[-2,:,:,:,:],axis=0),0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "boxed-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "interactive_map(['Pt_L','Ti_K'],stack,'rsm',np.log10(np.swapaxes(rsm.qxz_data,2,3)+1e-6),cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "necessary-essay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc2d3e1ad10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.log10(np.swapaxes(rsm.qxz_data,2,3)[11,25,:,:]+1e-7),cmap='jet',clim=[-4.8,-2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62a3b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive figure\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load fluorescence image stacks\n",
    "# insert your own code accordingly\n",
    "\n",
    "sum_Ge = np.sum(Ge,0)\n",
    "sum_W = np.sum(W,0)\n",
    "sum_Cu = np.sum(Cu,0)\n",
    "\n",
    "cmap = 'viridis'\n",
    "color = 'red'\n",
    "eps = 1e-5\n",
    "def onclick(event):\n",
    "    global row, col\n",
    "    col, row = event.xdata, event.ydata\n",
    "    if col is not None and row is not None:\n",
    "        row = int(np.round(row))\n",
    "        col = int(np.round(col))\n",
    "        ax0.clear()\n",
    "        ax0.imshow(sum_Ge,cmap=cmap)\n",
    "        ax0.plot(col,row,marker='o',markersize=2, color=color)\n",
    "        ax0.set_title('Ge')\n",
    "        ax1.clear()\n",
    "        ax1.imshow(sum_W,cmap=cmap)\n",
    "        ax1.plot(col,row,marker='o',markersize=2, color=color)\n",
    "        ax1.set_title('W')\n",
    "        ax2.clear()\n",
    "        ax2.imshow(sum_Cu,cmap=cmap)\n",
    "        ax2.plot(col,row,marker='o',markersize=2, color=color)\n",
    "        ax2.set_title('Cu')\n",
    "        ax3.clear()\n",
    "        ax3.imshow(rsm.tot,cmap=cmap)\n",
    "        ax3.plot(col,row,marker='o',markersize=2, color=color)\n",
    "        ax3.set_title('tot')\n",
    "        ax4.clear()\n",
    "        ax4.imshow(np.log10(rsm.qxz_data[row,col,:,:].T+eps),cmap=cmap)\n",
    "        ax4.set_title('RSM')\n",
    "        fig.canvas.draw_idle()\n",
    "    \n",
    "    return\n",
    "\n",
    "fig = plt.figure()\n",
    "spec = fig.add_gridspec(2,3)\n",
    "#fig, ax = plt.subplots(2,1)\n",
    "ax0 = fig.add_subplot(spec[0,0])\n",
    "ax0.imshow(clean_Ge,cmap=cmap)\n",
    "ax0.set_title('Ge')\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0,1])\n",
    "ax1.imshow(sum_W,cmap=cmap)\n",
    "ax1.set_title('W')\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0,2])\n",
    "ax2.imshow(sum_Cu,cmap=cmap)\n",
    "ax2.set_title('Cu')\n",
    "\n",
    "ax3 = fig.add_subplot(spec[1,0])\n",
    "ax3.imshow(rsm.tot,cmap=cmap)\n",
    "ax3.set_title('tot')\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1,1:3])\n",
    "ax4.imshow(np.log10(rsm.qxz_data[0,0,:,:].T+eps),cmap=cmap)\n",
    "ax4.set_title('RSM')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Call click func\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create movie\n",
    "import matplotlib\n",
    "import matplotlib.animation as manimation \n",
    "matplotlib.use('AGG') \n",
    "def update_fig(row,col):\n",
    "\n",
    "    #col = col + i\n",
    "    ax0.clear()\n",
    "    ax0.imshow(sum_Ge,cmap=cmap)\n",
    "    ax0.plot(col,row,marker='o',markersize=2, color=color)\n",
    "    ax0.set_title('Ge')\n",
    "    ax1.clear()\n",
    "    ax1.imshow(sum_W,cmap=cmap)\n",
    "    ax1.plot(col,row,marker='o',markersize=2, color=color)\n",
    "    ax1.set_title('W')\n",
    "    ax2.clear()\n",
    "    ax2.imshow(sum_Cu,cmap=cmap)\n",
    "    ax2.plot(col,row,marker='o',markersize=2, color=color)\n",
    "    ax2.set_title('Cu')\n",
    "    ax3.clear()\n",
    "    ax3.imshow(rsm.tot,cmap=cmap)\n",
    "    ax3.plot(col,row,marker='o',markersize=2, color=color)\n",
    "    ax3.set_title('tot')\n",
    "    ax4.clear()\n",
    "    ax4.imshow(np.log10(rsm.qxz_data[row,col,:,:].T+eps),cmap=cmap)\n",
    "    ax4.set_title('RSM')\n",
    "    fig.canvas.draw_idle()\n",
    "    return  \n",
    "     \n",
    "def init():\n",
    "    fig = plt.figure()\n",
    "    spec = fig.add_gridspec(2,3)\n",
    "    \n",
    "    ax0 = fig.add_subplot(spec[0,0])\n",
    "    ax0.imshow(clean_Ge,cmap=cmap)\n",
    "    ax0.set_title('Ge')\n",
    "\n",
    "    ax1 = fig.add_subplot(spec[0,1])\n",
    "    ax1.imshow(sum_W,cmap=cmap)\n",
    "    ax1.set_title('W')\n",
    "\n",
    "    ax2 = fig.add_subplot(spec[0,2])\n",
    "    ax2.imshow(sum_Cu,cmap=cmap)\n",
    "    ax2.set_title('Cu')\n",
    "\n",
    "    ax3 = fig.add_subplot(spec[1,0])\n",
    "    ax3.imshow(rsm.tot,cmap=cmap)\n",
    "    ax3.set_title('tot')\n",
    "\n",
    "    ax4 = fig.add_subplot(spec[1,1:3])\n",
    "    ax4.imshow(np.log10(rsm.qxz_data[0,0,:,:].T+eps),cmap=cmap)\n",
    "    ax4.set_title('RSM')\n",
    "    plt.tight_layout()\n",
    "    return  \n",
    "\n",
    "FFMpegWriter = manimation.writers['ffmpeg']\n",
    "metadata = dict(title='Movie', artist='hyan',\n",
    "                comment='RSM variation across GAAFET')\n",
    "writer = FFMpegWriter(fps=5, metadata=metadata)\n",
    "\n",
    "init()\n",
    "\n",
    "with writer.saving(fig, 'myfile.mp4', dpi=100):\n",
    "    writer.grab_frame()\n",
    "    row = 21\n",
    "    col = 5\n",
    "    for j in range(44):\n",
    "        update_fig(row,col+j)\n",
    "        writer.grab_frame()\n",
    "    row = 2\n",
    "    col = 28\n",
    "    for j in range(40):\n",
    "        update_fig(row+j,col)\n",
    "        writer.grab_frame()\n",
    "    #writer.finish()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
